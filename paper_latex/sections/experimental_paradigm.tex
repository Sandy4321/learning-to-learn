\section{Experimental Paradigm}
\label{sec:experimental_paradigm}
We first set out to model the infant learning tasks described by
\citet{Smith2002} using simple neural networks. During the study, 17-month-old
children were taught the names of primitive objects over the course of 7 weeks
via weekly play sessions. Objects in the study were 3D formations constructed of
various materials; each object contained a specific shape, color
and texture (material), and the names of the objects were organized stricly
by shape. During the weekly sessions, children played around with each object
while an adult announced the name of the object that they were playing with
repeatedly. By the end of the study, the children subjects had learned the
shape bias--i.e., they had formed the generalization that only objects with
the same shape have the same name. A control group of children, whom did not
partake in the play sessions, did not form the same generalization.

To model this study, we use artificial object datasets designed to
mimic the training data presented to the children subjects. We first perform
our computational experiments with with categorical bit-vector data, followed by
RGB images (the succeeding two sections, respectively). Each object sample is
assigned a shape, texture and color value. We train simple neural network
models to classify the shape of each object, providing labels that mimick
those provided to the children. To evaluate the generalization capabilities of
our models post-training, we use two generalization tests modeled after the two
tests used by \citet{Smith2002} to assess the children after training.

{\bf1. First-order generalization test}: For the first-order generalization
test, infants are first presented with a baseline object that they have seen and
played with during training. Then, they are presented with three novel objects
that have not been seen before: one that matches the baseline in shape, one
that matches in color, and one that matches in texture. For each of the three,
the other two feature dimensions are novel. The infants are asked to select
which of the three comparison objects share the same name as the baseline.
Performance is measured as the fraction of trials in which the child
selected the correct object, i.e. the shape match. We simulate this test by
creating an evaluation set containing groupings of four samples: a baseline, a
shape match, a color match, and a texture match. We find which of the three
samples the network thinks to be most similar by evaluating the cosine similarity
\footnote{Near-identical results were observed using Euclidean distance.}
using features at the highest hidden layer of the model. Accuracy is defined as
the fraction of groupings for which the model chose the correct (shape-similar)
object. This test was repeated for different training set sizes, i.e. different
combinations of \{\textit{\# categories}, \textit{\# exemplars}\}.

{\bf2. Second-order generalization test}: For the second-order generalization
test, infants are first presented with a baseline object that is novel in shape,
color and texture. From there, the trial proceeds similarly to those of the
first-order test: a shape match, color match and texture match are presented,
and the child must select which object she believes to share a name with the
baseline. All shapes, colors and textures are novel to the child in this test.
We simulate this test by creating an evaluation set... TODO.
This test was repeated for different training set
sizes, i.e. different combinations of \{\textit{\# categories},
\textit{\# exemplars}\}.

% mlp results
\begin{figure*}[h]
    \begin{center}
        % subfigure (a)
        \begin{subfigure}[b]{0.48\textwidth}
            \begin{center}
                \includegraphics[width=0.98\textwidth]
                {figures/mlp_o1_acc.pdf}
            \end{center}
        \end{subfigure}
        % subfigure (b)
        \begin{subfigure}[b]{0.48\textwidth}
            \begin{center}
                \includegraphics[width=0.98\textwidth]
                {figures/mlp_o2_acc.pdf}
            \end{center}
        \end{subfigure}
    \end{center}
    \caption{MLP generalization results for various training set sizes. Results
    show the average from 10 trials.}
    \label{fig:mlp_gen_results}
\end{figure*}

% mlp results
\begin{figure*}[h]
    \begin{center}
        % subfigure (a)
        \begin{subfigure}[b]{0.48\textwidth}
            \begin{center}
                \includegraphics[width=0.98\textwidth]
                {figures/cnn_o1_acc.pdf}
            \end{center}
        \end{subfigure}
        % subfigure (b)
        \begin{subfigure}[b]{0.48\textwidth}
            \begin{center}
                \includegraphics[width=0.98\textwidth]
                {figures/cnn_o2_acc.pdf}
            \end{center}
        \end{subfigure}
    \end{center}
    \caption{CNN generalization results for various training set sizes. Results
    show the average from 10 trials.}
    \label{fig:cnn_gen_results}
\end{figure*}