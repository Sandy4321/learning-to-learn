\section{Efficient Word Learning}
\label{sec:efficient_learning}
We first set out to model the infant learning tasks described in \cite{Smith2002} using
simple neural networks. In order to do so, we use artificial toy data that is designed
to mimic the training data described in the paper. Each object sample is assigned a shape,
texture and color value. There are two types of model evaluations performed, both drawn from
\cite{Smith2002}.

{\bf1. First-order generalization test}: For the first-order generalization test, infants
are asked to evaluate novel instances of familiar objects. To simulate this test, we train
our neural network models to classify objects, ensuring that objects of the same category
are assigned the same shape. Then, we build a test set by creating one novel exemplar of
each category that appeared in the training set. The novel exemplar has the same
shape as the training exemplars of that category, but a new color and texture combination.
Accuracy is defined as the fraction of test images that are correctly classified by the model.
This test is repeated for different training set sizes, i.e. different combinations of
\{\textit{\# categories}, \textit{\# exemplars}\}. It is important to note that as
\textit{\# categories} increases, the first-order task becomes more difficult.

{\bf2. Second-order generalization test}: For the second-order generalization test, infants
are presented with an exemplar of a novel object category as a baseline. Then, they are
shown 3 comparison objects: one which has the same shape as the baseline, one with the same
color, and one with the same texture. In each case, the other 2 features are different from
the baseline. The infants are asked to select which of the 3 comparison objects are of the
same category as the baseline object. We simulate this test by creating an evaluation set
containing groupings of 4 samples: the baseline, the shape constant, the color constant, and
the texture constant. Each grouping serves as one test example. We find which of the 3
samples the NN thinks to be most similar by evaluating the cosine similarity using the
hidden layer features of the model. Accuracy is defined as the fraction of groupings for
which the model chose the correct (shape-similar) object. This test was repeated for
different training set sizes, i.e. different combinations of \{\textit{\# categories},
\textit{\# exemplars}\}.

\begin{figure*}[h]
    \begin{center}
        % mlp results
        \begin{subfigure}[b]{0.47\textwidth}
            \begin{center}
                % subfigure (a)
                \begin{subfigure}[b]{0.48\textwidth}
                    \begin{center}
                        \includegraphics[width=0.98\textwidth]{figures/mlp_1order_accuracy.pdf}
                    \end{center}
                \end{subfigure}
                % subfigure (b)
                \begin{subfigure}[b]{0.48\textwidth}
                    \begin{center}
                        \includegraphics[width=0.98\textwidth]{figures/mlp_2order_accuracy.pdf}
                    \end{center}
                \end{subfigure}
            \end{center}
            \caption{MLP}
            \label{fig:mlp_results}
        \end{subfigure}
        % cnn results
        \begin{subfigure}[b]{0.47\textwidth}
            \begin{center}
                % subfigure (a)
                \begin{subfigure}[b]{0.48\textwidth}
                    \begin{center}
                        \includegraphics[width=\textwidth]{figures/cnn_1order_accuracy.pdf}
                    \end{center}
                \end{subfigure}
                % subfigure (b)
                \begin{subfigure}[b]{0.48\textwidth}
                    \begin{center}
                        \includegraphics[width=\textwidth]{figures/cnn_2order_accuracy.pdf}
                    \end{center}
                \end{subfigure}
            \end{center}
            \caption{CNN}
            \label{fig:cnn_results}
        \end{subfigure}
    \end{center}
    \caption{First- and second-order generalization results for the simple MLP and CNN models.
    For each \{\textit{\# categories}, \textit{\# exemplars}\} pair, the average result from
    5 trials is shown.}
    \label{fig:generalization_results}
\end{figure*}

\subsection{Simple Multilayer Perceptron}
To begin with, we use a simple multilayer perceptron (MLP) that operates on categorical
data. Since shape, color, \& texture have categorical feature values, we encode the values
using unique bit vectors that are randomly assigned at the beginning of the experiment. We
use a simple feed-forward NN with one hidden layer of 30 units, and the ReLU activation
function. The number of units in the softmax layer depends on the \textit{\# categories}
parameter for the particular dataset. Results are shown in Fig. \ref{fig:mlp_results}.

\subsection{Simple Convolutional Neural Network}
\label{sec:simple_cnn}
As a second type of model, we used a simple convolutional neural network (CNN) architecture
consisting of... TODO. To train this CNN, we generated images of artificial 2-D objects
(Fig. \ref{fig:generated_images}) with a variety of different shape, color and texture values. TODO... finish.
Results are shown in Fig. \ref{fig:cnn_results}.

\begin{figure}[h!]
    \begin{center}
        % shape 1
        \begin{subfigure}[b]{0.3\textwidth}
            \begin{center}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/generated_objects/img0000.png}
                \end{subfigure}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/generated_objects/img0001.png}
                \end{subfigure}
            \end{center}
        \end{subfigure}
        % % shape 2
        \begin{subfigure}[b]{0.3\textwidth}
            \begin{center}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/generated_objects/img0002.png}
                \end{subfigure}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/generated_objects/img0003.png}
                \end{subfigure}
            \end{center}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
            \begin{center}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/generated_objects/img0004.png}
                \end{subfigure}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/generated_objects/img0005.png}
                \end{subfigure}
            \end{center}
        \end{subfigure}
    \end{center}
    \caption{Computer-generated images of 2D objects with different shape, color and texture features.}
    \label{fig:generated_images}
\end{figure}

\section{Extensive Bias Analysis}
We next set out to analyze the biases of image classification models in detail. The model that
we choose to investigate is the popular VGG-16 network \cite{}, which has been pre-trained for
the ImageNet classification task.
% In addition to VGG-16, we also investigate the
% biases of our simple CNN from Section \ref{sec:efficient_learning}, trained on artificial objects with dataset
% dimensions \{\}.
Our analysis consists of two parts: 1) a detailed layer-wise investingation of the shape, color and
texture biases, and 2) a parametric analysis of the shape and color biases in these models.

\begin{figure}[h!]
    \begin{center}
        % shape 1
        \begin{subfigure}[b]{0.3\textwidth}
            \begin{center}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/artist_objects/fake1_carpet_red.jpg}
                \end{subfigure}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/artist_objects/fake1_sponge_yellow.jpg}
                \end{subfigure}
            \end{center}
        \end{subfigure}
        % % shape 2
        \begin{subfigure}[b]{0.3\textwidth}
            \begin{center}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/artist_objects/fake5_wood_pink.jpg}
                \end{subfigure}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/artist_objects/fake5_carpet_purple.jpg}
                \end{subfigure}
            \end{center}
        \end{subfigure}
        \begin{subfigure}[b]{0.3\textwidth}
            \begin{center}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/artist_objects/fake4_sponge_orange.jpg}
                \end{subfigure}
                \begin{subfigure}[b]{0.4\textwidth}
                    \includegraphics[width=\linewidth]{figures/artist_objects/fake4_wood_green.jpg}
                \end{subfigure}
            \end{center}
        \end{subfigure}
    \end{center}
    \caption{Artist-designed images of 3D objects with different shape, color and texture features.}
    \label{fig:artist_images}
\end{figure}

\begin{figure}[h!]
    \caption{CogPsyc images with different shape, color and texture features (TODO).}
    \label{fig:cogpsyc_images}
\end{figure}

\subsection{Layer-wise Biases}
The first step of our analysis is to evaluate the shape, color and texture biases of VGG-16
at each of its layers, in order to get a picture of how these biases develops along the
higherarchy of the model's internal representation. In order to probe the model, we make
use of two unique image datasets with stimuli that mimic \cite{Smith2002}.

{\bf1. Artist-generated object dataset}: These images were generated by an artist in Adobe
Photoshop. See Fig. \ref{fig:artist_images}.

{\bf2. CogPsyc object dataset}: These images were provided by cognitive psychologist Linda
Smith, and they were used in the experiments of \cite{Ritter2017}. See Fig.
\ref{fig:cogpsyc_images}.

\begin{figure*}[h]
    \begin{center}
        \begin{subfigure}[b]{0.4\textwidth}
            \begin{center}
                \includegraphics[width=\textwidth]{figures/vgg_layer_biases.pdf}
            \end{center}
            \caption{Artist-generated images}
            \label{fig:biases_artist}
        \end{subfigure}
        \begin{subfigure}[b]{0.4\textwidth}
            \caption{CogPsyc images (TODO)}
        \end{subfigure}
        \caption{VGG-16 layer-wise biases on two image datasets. Attention strength refers to
        the network's similarity score between the target objectand objects that match in
        either shape, color or texture.}
    \end{center}
    \label{fig:layerwise_biases}
\end{figure*}

The layer-wise bias results are shown in Fig. \ref{fig:biases_artist}.

\subsection{Parametric Biases}
The second step of our analysis is to examine how the shape and color biases depend on the intensity
of their respective feature similarities. For these tests, we make use of our computer-generated
images so that we can quantitatively manipulate and evaluate the shape and color features of our
objects. The parametric bias results are shown in Fig. \ref{fig:parametric_others_constant} and
\ref{fig:parametric_others_varying}.
\begin{figure}[h!]
    \begin{center}
        \begin{subfigure}[b]{0.235\textwidth}
            \includegraphics[width=\linewidth]{figures/vgg_shape_parametric_others_constant.pdf}
            \caption{Shape}
        \end{subfigure}
        \begin{subfigure}[b]{0.235\textwidth}
            \includegraphics[width=\linewidth]{figures/vgg_color_parametric_others_constant.pdf}
            \caption{Color}
        \end{subfigure}
    \end{center}
    \caption{VGG-16 parametric shape and color biases w/ other features constant.}
    \label{fig:parametric_others_constant}
\end{figure}

\begin{figure}[h!]
    \begin{center}
        \begin{subfigure}[b]{0.235\textwidth}
            \includegraphics[width=\linewidth]{figures/vgg_shape_parametric.pdf}
            \caption{Shape}
        \end{subfigure}
        \begin{subfigure}[b]{0.235\textwidth}
            \includegraphics[width=\linewidth]{figures/vgg_color_parametric.pdf}
            \caption{Color}
        \end{subfigure}
    \end{center}
    \caption{VGG-16 parametric shape and color biases w/ other features varying.}
    \label{fig:parametric_others_varying}
\end{figure}
