{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_imgs(save_folder):\n",
    "    imgs = []\n",
    "    files = [file for file in os.listdir(save_folder) if file.endswith('png')]\n",
    "    for file in files:\n",
    "        img_path = os.path.join(save_folder, file)\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        imgs.append(image.img_to_array(img))\n",
    "    \n",
    "    return preprocess_input(np.asarray(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_images('../data/image_dataset')\n",
    "df = pd.read_csv('../data/image_dataset/data.csv', index_col=0)\n",
    "labels = df['shape'].as_matrix()\n",
    "nb_samples = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 224, 224, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = image.img_to_array(img)\n",
    "# print(x.shape)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_h = model.predict(X)\n",
    "X_h = X_h.reshape(nb_samples,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 25088)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def similarity(x1, x2):\n",
    "    return 1 - cosine(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62544033557873402"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(X_h[0], X_h[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(X, i):\n",
    "    \"\"\"\n",
    "    :param X: The (nb_samples, nb_features) feature matrix.\n",
    "    :param i: The index of the sample we want to compare to others.\n",
    "    \"\"\"\n",
    "    candidates = list(range(len(X)))\n",
    "    candidates.remove(i)\n",
    "    for j in candidates:\n",
    "        print('%0.2i: %0.3f' % (j, similarity(X[i], X[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(X, y):\n",
    "    means_same = []\n",
    "    means_diff = []\n",
    "    max_in = 0\n",
    "    for i, cat in enumerate(y):\n",
    "        # Find indices of other samples with same category\n",
    "        inds_same = np.where(y == cat)[0]\n",
    "        vals_same = [similarity(X[i], X[j]) for j in inds_same]\n",
    "        # Find indices of other samples with different category\n",
    "        inds_diff = np.where(y != cat)[0]\n",
    "        vals_diff = [similarity(X[i], X[j]) for j in inds_diff]\n",
    "        if max(vals_same) > max(vals_diff):\n",
    "            max_in += 1\n",
    "        means_same.append(np.mean(vals_same))\n",
    "        means_diff.append(np.mean(vals_diff))\n",
    "            \n",
    "    return np.mean(means_same), np.mean(means_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82893847426332068, 0.25640831696766686)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X_h, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot images side by side for the github wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import imread\n",
    "\n",
    "imgs = np.asarray(\n",
    "    [imread(os.path.join('../data/image_dataset', 'img%0.4i.png' % i)) \n",
    "     for i in range(20)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400, 400, 4)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(3, 2, figsize=(15, 20))\n",
    "# ax[0,0].imshow(imgs[0])\n",
    "# ax[0,1].imshow(imgs[1])\n",
    "# ax[1,0].imshow(imgs[2])\n",
    "# ax[1,1].imshow(imgs[3])\n",
    "# ax[2,0].imshow(imgs[12])\n",
    "# ax[2,1].imshow(imgs[13])\n",
    "# ax[0,0].title.set_text('Shape 0, Color 1, Texture 1') #0\n",
    "# ax[0,1].title.set_text('Shape 0, Color 9, Texture 5') #1\n",
    "# ax[1,0].title.set_text('Shape 1, Color 3, Texture 0') #2\n",
    "# ax[1,1].title.set_text('Shape 1, Color 7, Texture 9') #3\n",
    "# ax[2,0].title.set_text('Shape 6, Color 1, Texture 7') #12\n",
    "# ax[2,1].title.set_text('Shape 6, Color 4, Texture 7') #13\n",
    "# ax[0,0].axis('off')\n",
    "# ax[0,1].axis('off')\n",
    "# ax[1,0].axis('off')\n",
    "# ax[1,1].axis('off')\n",
    "# ax[2,0].axis('off')\n",
    "# ax[2,1].axis('off')\n",
    "# plt.show()\n",
    "# f.savefig('../data/image_examples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
