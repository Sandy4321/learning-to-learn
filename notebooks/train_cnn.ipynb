{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def load_and_preprocess_imgs_brenden():\n",
    "    save_folder = '../data/images_brenden/'\n",
    "    shapes = []\n",
    "    colors = []\n",
    "    textures = []\n",
    "    imgs = []\n",
    "    files = [file for file in os.listdir(save_folder) \n",
    "             if file.endswith('jpg') or file.endswith('png')]\n",
    "    for file in files:\n",
    "        shape, texture, color = file.split('_')\n",
    "        color = color[:-4]\n",
    "        shapes.append(shape)\n",
    "        textures.append(texture)\n",
    "        colors.append(color)\n",
    "        img_path = os.path.join(save_folder, file)\n",
    "        #img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img = image.load_img(img_path, target_size=(32, 32))\n",
    "        imgs.append(image.img_to_array(img))\n",
    "    imgs = np.asarray(imgs)\n",
    "    imgs /= 255.\n",
    "        \n",
    "    le = LabelEncoder()\n",
    "    shapes = le.fit_transform(shapes)\n",
    "    colors = le.fit_transform(colors)\n",
    "    textures = le.fit_transform(textures)\n",
    "    \n",
    "    return imgs, shapes, colors, textures\n",
    "\n",
    "def data_cifar10():\n",
    "    \"\"\"\n",
    "    Preprocess CIFAR-10 dataset\n",
    "    \"\"\"\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, shapes, colors, textures = load_and_preprocess_imgs_brenden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "Y = ohe.fit_transform(shapes.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABNBJREFUeJztms+LHEUUxz+vqnvGWbO7CYk5mOjFKJhIEPUSI7nkKujF\niydF9BBBQXOIIojg2b/Bs4qgUfEuYkDiLYHIGjUkRMzvH5v9MdNdHl71zEaF3cHJs0ff59I91V3V\nXd/59quq1y0pJRw7wr99A/83XHBjXHBjXHBjXHBjXHBjXHBjXHBjXHBjCuPr/ZeXtbKRk9zhxrjg\nxrjgxrjgxrjgxrjgxrjgxrjgxrjgxrjgxrjgxrjgxrjgxlhnC8di6foHACQpkPIaAFKrR1Jz66lE\nUi7L+bpYJeKmg7of9hre8fqI8YdAY11s6caRXKskiaopzGhZ/o0krtx6C4BOpcfunnuXUOsfMigW\nAQjVHACxPEhZPnJbExPC07NtpNUOX778BgASErU00S97RKJuJJIk3HYsEZCgl7p28X0ANm9/W4/V\nM1DPAtDb9HyuNz9uP/4Od3gbabXDV39/EYDLJz9ky+5D2kDnFgBlugJAX3YNmxVpBs84HFSbsjp7\nSyQOnw5kFYBu8RwAobNn/B6NcIe3kVY7fHD+WQCqmJC6C8DNSx8DUEY1VNGJxLkX9DxZ6+JitA/U\neepI6iCF5Jtpngg9d2b2MLBp7E5lNuTwdgt+9imtlEpESgCqmAW8/jUA3dln6Mcy18hTx9BZE0JU\nzMXfvgEgFgt0th/Kx5rQkrepS3fLe7ml7lgdw0NKO2m1w/u/7AdA6MPacIEOjNpgOXRoCnmqSLGm\nLIePpn6aYanXByCe/wSAcpsOzjUFP3/6EQC7X740bt/c4W2k1bmUsj4DwOqvZwn3PwxACtmpqIOD\nCHXQeCtV4+ZyFJ8ZLZC0/i16i3lAnXtaywZX9UwpWKwua7XmWZzs8r/dglf1EwCUOypSfUMLc/Kq\nOq1/hjywC5FlAAZnTus5RZ9i56O63wifw02qIxKaxFf+06L+XiYQ63xx6eedZkCeDB5SjGn1oFll\nt4VTW0eDXpPiy4MhKUKTns1l1fULxPkdWiZ/CikE6kJdmwZaL2THn/jy+DBU7X11dbye+aDZTlod\nw+PQDvXo2UijImUwPL9xZ5ydQwY3tWw4VcwLJgmEn84CsNLTRjo7d+WWEo+/Mrazx8IdbkyrHd6Q\nUg9kZd3zJNv/2NGrxFK99Ni+CoAwqzlvkYjctw2AXo75xz9f0Aa6THpS8hemQnCRwSiSXNC0bLhn\nix6LNd8f1ddoKb9W68cB+17LNU7kufkwJFWILAFwbqEDwIpu2P9SdQd7oXhIMWYqHF4NuoRCXzyE\n7RoaUh41j322OHzJMFhR5x54Z83sc09+OXFyq9YTSEHjxrkF/RKgt5x9V9x5/7nDjWn1wmdI3af+\n8V4Avv3iIjBySiVw4M31m11F8yVy6iF++OoCAIOgwXv/6+sPyBvAFz5tZCpiOKHku+zsFTUqd81r\nhvDA4ZsbaqLDZt158BxLXXX2k4cm4uyxmI6QAiSaFaAOjPJPviWpmyTNRB9wDyltZGocPgW4w9uI\nC26MC26MC26MC26MC26MC26MC26MC26MC26MC26MdXp2wp9GTh/ucGNccGNccGNccGNccGNccGNc\ncGNccGNccGNccGNccGNccGNccGNccGNccGNccGNccGNccGNccGNccGNccGNccGNccGP+ABLzN7pT\nIHQnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128bab198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(X[5], interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "80/80 [==============================] - 1s - loss: 20.5907 - acc: 0.1375     \n",
      "Epoch 2/80\n",
      "80/80 [==============================] - 0s - loss: 15.5593 - acc: 0.0625     \n",
      "Epoch 3/80\n",
      "80/80 [==============================] - 0s - loss: 12.6941 - acc: 0.1875     \n",
      "Epoch 4/80\n",
      "80/80 [==============================] - 0s - loss: 10.6238 - acc: 0.1250     \n",
      "Epoch 5/80\n",
      "80/80 [==============================] - 0s - loss: 8.9861 - acc: 0.1500     \n",
      "Epoch 6/80\n",
      "80/80 [==============================] - 0s - loss: 7.6573 - acc: 0.1125     \n",
      "Epoch 7/80\n",
      "80/80 [==============================] - 0s - loss: 6.5653 - acc: 0.1875     \n",
      "Epoch 8/80\n",
      "80/80 [==============================] - 0s - loss: 5.6648 - acc: 0.1625     \n",
      "Epoch 9/80\n",
      "80/80 [==============================] - 0s - loss: 4.9182 - acc: 0.1750     \n",
      "Epoch 10/80\n",
      "80/80 [==============================] - 0s - loss: 4.3310 - acc: 0.1250     \n",
      "Epoch 11/80\n",
      "80/80 [==============================] - 0s - loss: 3.8423 - acc: 0.1750     \n",
      "Epoch 12/80\n",
      "80/80 [==============================] - 0s - loss: 3.4570 - acc: 0.1750     \n",
      "Epoch 13/80\n",
      "80/80 [==============================] - 0s - loss: 3.1534 - acc: 0.1250     \n",
      "Epoch 14/80\n",
      "80/80 [==============================] - 0s - loss: 2.8998 - acc: 0.1875     \n",
      "Epoch 15/80\n",
      "80/80 [==============================] - 0s - loss: 2.6882 - acc: 0.1625     \n",
      "Epoch 16/80\n",
      "80/80 [==============================] - 0s - loss: 2.7507 - acc: 0.1375     \n",
      "Epoch 17/80\n",
      "80/80 [==============================] - 0s - loss: 2.4978 - acc: 0.1625     \n",
      "Epoch 18/80\n",
      "80/80 [==============================] - 0s - loss: 2.3976 - acc: 0.1625     \n",
      "Epoch 19/80\n",
      "80/80 [==============================] - 0s - loss: 2.3288 - acc: 0.1625     \n",
      "Epoch 20/80\n",
      "80/80 [==============================] - 0s - loss: 2.2779 - acc: 0.1375     \n",
      "Epoch 21/80\n",
      "80/80 [==============================] - 0s - loss: 2.2331 - acc: 0.1625     \n",
      "Epoch 22/80\n",
      "80/80 [==============================] - 0s - loss: 2.2003 - acc: 0.1625     \n",
      "Epoch 23/80\n",
      "80/80 [==============================] - 0s - loss: 2.1707 - acc: 0.1625     \n",
      "Epoch 24/80\n",
      "80/80 [==============================] - 0s - loss: 2.1429 - acc: 0.1625     \n",
      "Epoch 25/80\n",
      "80/80 [==============================] - 0s - loss: 2.0443 - acc: 0.2500     \n",
      "Epoch 26/80\n",
      "80/80 [==============================] - 0s - loss: 2.1079 - acc: 0.1625     \n",
      "Epoch 27/80\n",
      "80/80 [==============================] - 0s - loss: 1.8645 - acc: 0.3250     \n",
      "Epoch 28/80\n",
      "80/80 [==============================] - 0s - loss: 1.7621 - acc: 0.4000     \n",
      "Epoch 29/80\n",
      "80/80 [==============================] - 0s - loss: 1.6871 - acc: 0.4000     \n",
      "Epoch 30/80\n",
      "80/80 [==============================] - 0s - loss: 1.5117 - acc: 0.4375     \n",
      "Epoch 31/80\n",
      "80/80 [==============================] - 0s - loss: 1.4214 - acc: 0.5625     \n",
      "Epoch 32/80\n",
      "80/80 [==============================] - 0s - loss: 1.5273 - acc: 0.5000     \n",
      "Epoch 33/80\n",
      "80/80 [==============================] - 0s - loss: 1.0131 - acc: 0.7250     \n",
      "Epoch 34/80\n",
      "80/80 [==============================] - 0s - loss: 1.6791 - acc: 0.6250     \n",
      "Epoch 35/80\n",
      "80/80 [==============================] - 0s - loss: 0.8161 - acc: 0.8250     \n",
      "Epoch 36/80\n",
      "80/80 [==============================] - 0s - loss: 1.2247 - acc: 0.6125     \n",
      "Epoch 37/80\n",
      "80/80 [==============================] - 0s - loss: 0.7552 - acc: 0.8875     \n",
      "Epoch 38/80\n",
      "80/80 [==============================] - 0s - loss: 1.2979 - acc: 0.7125     \n",
      "Epoch 39/80\n",
      "80/80 [==============================] - 0s - loss: 0.4698 - acc: 0.9750     \n",
      "Epoch 40/80\n",
      "80/80 [==============================] - 0s - loss: 0.4455 - acc: 0.9375     \n",
      "Epoch 41/80\n",
      "80/80 [==============================] - 0s - loss: 0.6117 - acc: 0.9125     \n",
      "Epoch 42/80\n",
      "80/80 [==============================] - 0s - loss: 0.4610 - acc: 0.9375     \n",
      "Epoch 43/80\n",
      "80/80 [==============================] - 0s - loss: 0.3807 - acc: 0.9750     \n",
      "Epoch 44/80\n",
      "80/80 [==============================] - 0s - loss: 0.4230 - acc: 0.9625     \n",
      "Epoch 45/80\n",
      "80/80 [==============================] - 0s - loss: 0.3292 - acc: 0.9750     \n",
      "Epoch 46/80\n",
      "80/80 [==============================] - 0s - loss: 0.2803 - acc: 1.0000     \n",
      "Epoch 47/80\n",
      "80/80 [==============================] - 0s - loss: 0.2598 - acc: 1.0000     \n",
      "Epoch 48/80\n",
      "80/80 [==============================] - 0s - loss: 0.2424 - acc: 1.0000     \n",
      "Epoch 49/80\n",
      "80/80 [==============================] - 0s - loss: 0.2304 - acc: 1.0000     \n",
      "Epoch 50/80\n",
      "80/80 [==============================] - 0s - loss: 0.5788 - acc: 0.8625     \n",
      "Epoch 51/80\n",
      "80/80 [==============================] - 0s - loss: 0.9720 - acc: 0.7500     \n",
      "Epoch 52/80\n",
      "80/80 [==============================] - 0s - loss: 0.3080 - acc: 1.0000     \n",
      "Epoch 53/80\n",
      "80/80 [==============================] - 0s - loss: 0.2730 - acc: 1.0000     \n",
      "Epoch 54/80\n",
      "80/80 [==============================] - 0s - loss: 0.2819 - acc: 0.9875     \n",
      "Epoch 55/80\n",
      "80/80 [==============================] - 0s - loss: 0.2426 - acc: 1.0000     \n",
      "Epoch 56/80\n",
      "80/80 [==============================] - 0s - loss: 0.2287 - acc: 1.0000     \n",
      "Epoch 57/80\n",
      "80/80 [==============================] - 0s - loss: 0.2831 - acc: 0.9625     \n",
      "Epoch 58/80\n",
      "80/80 [==============================] - 0s - loss: 0.5214 - acc: 0.9000     \n",
      "Epoch 59/80\n",
      "80/80 [==============================] - 0s - loss: 0.3372 - acc: 0.9625     \n",
      "Epoch 60/80\n",
      "80/80 [==============================] - 0s - loss: 0.2408 - acc: 1.0000     \n",
      "Epoch 61/80\n",
      "80/80 [==============================] - 0s - loss: 0.2215 - acc: 1.0000     \n",
      "Epoch 62/80\n",
      "80/80 [==============================] - 0s - loss: 0.2115 - acc: 1.0000     \n",
      "Epoch 63/80\n",
      "80/80 [==============================] - 0s - loss: 0.2227 - acc: 0.9875     \n",
      "Epoch 64/80\n",
      "80/80 [==============================] - 0s - loss: 0.2217 - acc: 0.9875     \n",
      "Epoch 65/80\n",
      "80/80 [==============================] - 0s - loss: 0.1809 - acc: 1.0000     \n",
      "Epoch 66/80\n",
      "80/80 [==============================] - 0s - loss: 0.1682 - acc: 1.0000     \n",
      "Epoch 67/80\n",
      "80/80 [==============================] - 0s - loss: 0.1528 - acc: 1.0000     \n",
      "Epoch 68/80\n",
      "80/80 [==============================] - 0s - loss: 0.4114 - acc: 0.9375     \n",
      "Epoch 69/80\n",
      "80/80 [==============================] - 0s - loss: 0.6862 - acc: 0.8875     \n",
      "Epoch 70/80\n",
      "80/80 [==============================] - 0s - loss: 0.2776 - acc: 0.9875     \n",
      "Epoch 71/80\n",
      "80/80 [==============================] - 0s - loss: 0.1969 - acc: 1.0000     \n",
      "Epoch 72/80\n",
      "80/80 [==============================] - 0s - loss: 0.1805 - acc: 1.0000     \n",
      "Epoch 73/80\n",
      "80/80 [==============================] - 0s - loss: 0.1639 - acc: 1.0000     \n",
      "Epoch 74/80\n",
      "80/80 [==============================] - 0s - loss: 0.1505 - acc: 1.0000     \n",
      "Epoch 75/80\n",
      "80/80 [==============================] - 0s - loss: 0.1407 - acc: 1.0000     \n",
      "Epoch 76/80\n",
      "80/80 [==============================] - 0s - loss: 0.2904 - acc: 0.9625     \n",
      "Epoch 77/80\n",
      "80/80 [==============================] - 0s - loss: 0.1664 - acc: 1.0000     \n",
      "Epoch 78/80\n",
      "80/80 [==============================] - 0s - loss: 0.1408 - acc: 1.0000     \n",
      "Epoch 79/80\n",
      "80/80 [==============================] - 0s - loss: 0.1264 - acc: 1.0000     \n",
      "Epoch 80/80\n",
      "80/80 [==============================] - 0s - loss: 0.1163 - acc: 1.0000     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129cd3908>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from learning2learn.models import simple_cnn\n",
    "\n",
    "input_shape = X.shape[1:]\n",
    "nb_classes = len(np.unique(shapes))\n",
    "model = simple_cnn(input_shape, nb_classes)\n",
    "model.fit(X, Y, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
